{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glicko-2 Reward Function for Nectar Dataset\n",
    "\n",
    "This notebook implements a reward function based on Glicko-2 ratings for the Berkeley NEST Nectar dataset. The reward function is defined as:\n",
    "\n",
    "```\n",
    "Reward = Glicko-2 Rating - Rating Volatility\n",
    "```\n",
    "\n",
    "This rewards items with high ratings while penalizing those with high volatility (inconsistency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets glicko2 matplotlib pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from glicko2 import Player\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the Nectar Dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Berkeley NEST Nectar dataset...\n",
      "Dataset loaded with 182954 entries.\n",
      "\n",
      "Dataset Structure:\n",
      "Dictionary with keys: ['train']\n",
      "Train set length: 182954\n",
      "\n",
      "Detailed Exploration of First 3 Records:\n",
      "\n",
      "===== Record 0 =====\n",
      "Keys: ['prompt', 'answers', 'turns', 'num_responses', 'source', 'good_natured']\n",
      "{\n",
      "  \"prompt\": \"\\n\\nHuman: 0.002 = 1000 \\n1 = x?\\n\\nAssistant: \",\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"answer\": \"To find the value of x, we can set up a proportion using the given information:\\n\\n0.002/1000 = 1/x\\n\\nTo solve for x, we can cross multiply:\\n\\n0.002 * x = 1000 * 1\\n\\n0.002x = 1000\\n\\nDividing both sides by 0.002:\\n\\nx = 1000 / 0.002\\n\\nx = 500,000\\n\\nTherefore, 1 is equal to 500,000 in this proportion.\",\n",
      "      \"model\": \"gpt-3.5-turbo\",\n",
      "      \"rank\": 1.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"To solve for x in this equation, you can use cross-multiplication. Here's how:\\n\\n0.002 / 1 = 1000 / x\\n\\nCross-multiplication gives:\\n\\n0.002 * x = 1000\\n\\nTo solve for x, divide both sides by 0.002:\\n\\nx = 1000 / 0.002\\n\\nSo, x equals 500,000.\",\n",
      "      \"model\": \"gpt-4-0613\",\n",
      "      \"rank\": 2.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"This looks like a proportion. To solve for x, you can set up a proportion equation:\\n\\n0.002 / 1 = 1000 / x\\n\\nNow, cross-multiply:\\n\\n0.002 \\\\* x = 1 \\\\* 1000\\n\\nThen, solve for x:\\n\\n0.002x = 1000\\n\\nx = 1000 / 0.002\\n\\nx = 500,000\",\n",
      "      \"model\": \"gpt-3.5-turbo\",\n",
      "      \"rank\": 3.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"If 0.002 equals 1000, then 1 would equal 500,000.\",\n",
      "      \"model\": \"gpt-4\",\n",
      "      \"rank\": 4.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"I apologize, but the equation you provided is not correct.\\n\\n0.002 is equal to 0.002, not 1000.\\n\\n1 is equal to x, not a number.\\n\\nCan you please provide a correct equation or problem for me to solve?\",\n",
      "      \"model\": \"llama-2-7b-chat\",\n",
      "      \"rank\": 5.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"0.001 = x\",\n",
      "      \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "      \"rank\": 6.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"It seems like you are asking for the value of x in the equation x = 1/0.002. \\n\\nTo solve this equation, you can divide both sides by 0.002 to get: \\n\\nx = 1/0.002 \\nx = 500 \\n\\nTherefore, x = 500.\",\n",
      "      \"model\": \"mistral-7b-instruct-v0.1\",\n",
      "      \"rank\": 7.0\n",
      "    }\n",
      "  ],\n",
      "  \"turns\": 1,\n",
      "  \"num_responses\": 7,\n",
      "  \"source\": [\n",
      "    \"sharegpt\"\n",
      "  ],\n",
      "  \"good_natured\": true\n",
      "}\n",
      "\n",
      "===== Record 1 =====\n",
      "Keys: ['prompt', 'answers', 'turns', 'num_responses', 'source', 'good_natured']\n",
      "{\n",
      "  \"prompt\": \"\\n\\nHuman: 0:00\\nwhat's going on guys it's NAME_1 from\\n0:01\\nNAME_2 and today we're going to\\n0:03\\ntalk about cns fatigue\\n0:05\\nso going over uh cns fatigue central\\n0:07\\nnervous system fatigue it's something\\n0:08\\nthat people talk about and bring up a\\n0:10\\nlot\\n0:10\\nthere's a bit of science to it and\\n0:12\\nthere's also a lot of bro\\n0:13\\nculture myth to it and i want to get\\n0:15\\ninto that and i'm i'm going to talk\\n0:17\\nreally quick about where it comes from\\n0:19\\nwhy we talk about it this way and then\\n0:21\\nhow it kind of gets used and misused\\n0:23\\nto describe a certain training\\n0:25\\nphenomenon that we all experience\\n0:27\\nso i'm going to start out by kind of\\n0:29\\nfleshing out what we're talking about or\\n0:31\\nhow it kind of originally became\\n0:34\\ndiscussed about so we observe a few\\n0:35\\nthings when it comes to weight training\\n0:37\\nspecifically with lifting heavy\\n0:38\\nthe first thing we observe is that true\\n0:40\\nmaximal attempts at 90\\n0:42\\nand up rpe nine to ten so that's really\\n0:45\\nhard triples double singles that's\\n0:46\\nkind of a broad identifier of what\\n0:48\\nmaximal work is\\n0:50\\nuh if you do that every session for the\\n0:52\\nsame lift it's going to lead to\\n0:54\\nshort-term regression\\n0:55\\nnow this might be something that you all\\n0:57\\nhave experienced at some point\\n0:59\\nif you were lifting maximally several\\n1:01\\nweeks in a row and you started to get a\\n1:02\\nlittle bit stronger\\n1:04\\nand you got really psyched you were\\n1:05\\nprimed for this big pr and you went in\\n1:07\\nand you felt great and then just\\n1:09\\neverything moved like crap it just moved\\n1:11\\nslowly you couldn't handle the loads you\\n1:12\\ncould last week\\n1:13\\nand if you're anything like me got\\n1:14\\nfrustrated you took your ball and went\\n1:16\\nhome\\n1:17\\nthat is an observation that has been\\n1:19\\nseen\\n1:20\\nin pretty much all strength sports it's\\n1:22\\nsomething that has been uh\\n1:24\\naccounted for for a very long time and\\n1:26\\nit's the reason that the wisdom is now\\n1:28\\nlike don't NAME_3 out every week it's not\\n1:30\\nsustainable\\n1:31\\nin the short term if it's the same lift\\n1:33\\nyou're training in this threshold every\\n1:35\\nsession\\n1:36\\nyou're going to see regression\\n1:38\\neventually which is why you see\\n1:40\\na lot of uh patterning that's so common\\n1:42\\nnow with regards to either deloads or\\n1:44\\ncertain wave schemes that kind of push\\n1:46\\nthose attempts apart\\n1:47\\nthe other thing we observe is that the\\n1:48\\ntime between contest day\\n1:50\\nand the last heavy attempt so you have\\n1:52\\nthe contest this is the last heavy\\n1:54\\nattempt you did\\n1:55\\nit tends to be a lot farther a lot more\\n1:58\\ntime\\n\\nAssistant: \",\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"answer\": \"Hello! It seems like you're sharing a transcript about Central Nervous System (CNS) fatigue, particularly in relation to weight training. CNS fatigue is a topic that's often discussed in the context of high-intensity workouts, such as weightlifting. \\n\\nThe transcript you've shared discusses the concept of CNS fatigue, its origins, and how it's often misused to describe certain training phenomena. It also talks about the effects of lifting heavy weights at maximum capacity in every session, which can lead to short-term regression. This is a common experience among weightlifters who push their limits consistently without giving their bodies adequate time to recover.\\n\\nThe speaker also mentions the common practice of spacing out heavy lifting sessions or incorporating deload periods to prevent this regression. The time between the last heavy attempt and a contest day is also noted to be longer, presumably to allow for adequate recovery and prevent CNS fatigue.\\n\\nIf you have any specific questions about this topic or if there's a particular aspect you'd like to discuss further, feel free to ask!\",\n",
      "      \"model\": \"gpt-4-0613\",\n",
      "      \"rank\": 1.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"0:00\\nHey there! Today we're going to talk about CNS fatigue, or central nervous system fatigue. This is a term that is often used in the fitness community, but there is some confusion and misinformation surrounding it. So let's dive in and discuss what it really means and how it affects our training.\\n\\nFirst, let's define what we mean by CNS fatigue. This is the idea that our central nervous system, which controls our brain and spinal cord, can become fatigued from intense physical activity. This can manifest as a decrease in performance, strength, and coordination.\\n\\nOne of the main observations that has led to the concept of CNS fatigue is that when we lift heavy weights at a high intensity, such as a 9 or 10 on the RPE scale, we tend to see short-term regression in our performance. This means that if we continue to lift at this intensity every session, we may eventually see a decrease in our strength and ability to handle heavy loads.\\n\\nAdditionally, we also see that the time between a competition and the last heavy attempt can have an impact on our performance. If we have a long period of time between these two events, we may see a decrease in our strength and coordination.\\n\\nSo why does this happen? Well, when we lift heavy weights, our central nervous system is heavily involved in coordinating and controlling our muscles. This requires a lot of energy and resources, and if we continue to push our CNS to its limits, it can become fatigued and unable to perform at its best.\\n\\nSo how can we prevent CNS fatigue? One way is to vary our training intensity and not constantly lift at a 9 or 10 RPE. We can also incorporate deloads and wave schemes into our training to give our CNS a break and allow it to recover.\\n\\nIn conclusion, CNS fatigue is a real phenomenon that can affect our performance in the gym. By understanding it and implementing strategies to prevent it, we can continue to make progress and reach our fitness goals. Thanks for listening!\",\n",
      "      \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "      \"rank\": 2.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"It seems like you're discussing the concept of Central Nervous System (CNS) fatigue in relation to weight training. CNS fatigue refers to the idea that intense physical activity, particularly heavy weightlifting, can cause the central nervous system to become tired, leading to a decrease in athletic performance. \\n\\nYou've mentioned that lifting at maximum capacity (90% and up, or RPE 9 to 10) in every session can lead to short-term regression, meaning that your performance may decrease over time. This is a common observation in strength sports, and it's why many trainers recommend not lifting at maximum capacity in every session. \\n\\nYou've also mentioned that the time between the last heavy attempt and the day of the competition tends to be longer. This is likely to allow the body, including the CNS, to recover and perform at its best during the competition. \\n\\nIt's important to note that while CNS fatigue is a commonly discussed concept in the fitness community, the scientific understanding of it is still evolving. Some believe that what is often attributed to CNS fatigue may actually be due to other factors, such as muscle damage or psychological burnout. \\n\\nRemember, it's always important to listen to your body and give it adequate rest and recovery time to prevent overtraining and potential injury.\",\n",
      "      \"model\": \"gpt-4\",\n",
      "      \"rank\": 3.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"It seems like you're discussing CNS fatigue and its effects on weight training. CNS fatigue, or central nervous system fatigue, is a phenomenon that occurs when the central nervous system becomes overworked and fatigued due to intense physical activity. This can lead to a decrease in performance and strength.\\n\\nYou mentioned that consistently lifting at maximal intensity (RPE 9-10) can lead to short-term regression in strength. This is a common observation in strength sports, and it's why it's recommended not to go all out every week. Instead, incorporating deloads or wave schemes can help manage CNS fatigue and prevent regression.\\n\\nIt's important to note that CNS fatigue is a complex topic, and there is both scientific evidence and bro culture myths surrounding it. It's essential to understand the science behind it and how it applies to your training to avoid misusing the concept.\\n\\nIf you have any specific questions or need further information, feel free to ask!\",\n",
      "      \"model\": \"gpt-3.5-turbo\",\n",
      "      \"rank\": 4.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"0:00\\nin the past\\n0:00\\nwith the same lift\\n0:00\\nand the same weight\\n0:00\\nand the same load\\n0:00\\nthen\\n0:00\\nif you have a deload day and you come back\\n0:00\\nand you're feeling like you can handle\\n0:00\\n heavier loads\\n0:00\\nwith a little bit more energy\\n0:00\\nthen the load is typically a little bit\\n0:01\\n lighter than the previous day's load\\n0:02\\nand the time between contest day and the\\n0:03\\nlast heavy attempt\\n0:03\\nis typically a lot shorter\\n0:04\\nthan the time between the previous day's\\n0:05\\nheavy attempt and the contest day\\n0:06\\nand that's a general observation that has\\n0:08\\nalso been seen in other strength training\\n0:09\\nstyles\\n0:10\\nand it's something that's been uh\\n0:12\\naccounted for in the wisdom of\\n0:13\\n trainers and coaches over the years\\n0:14\\nand it's a good idea to keep in mind when\\n0:16\\nyou're lifting heavy or you're training in\\n0:17\\na deloads schedule\\n0:18\\nand you have a lot of energy and you're\\n0:20\\nable to handle heavier loads\\n0:21\\nthe load is typically a little bit\\n0:22\\n lighter than the previous day's load\\n0:23\\nand the time between contest day and the\\n0:25\\nlast heavy attempt is typically a lot\\n0:26\\n shorter than the time between the previous\\n0:27\\nday's heavy attempt and the contest day\\n0:28\\nand that's a general observation that has\\n0:30\\nalso been seen in other strength training\\n0:31\\nstyles\\n0:32\\nand it's important to keep in mind when\\n0:34\\nyou're lifting heavy or you're training in\\n0:35\\na deloads schedule\\n0:36\\nand you have a lot of energy and you're able\\n0:38\\nto handle heavier loads\\n0:39\\nthe load is typically a little bit\\n0:40\\n lighter than the previous day's load\\n0:41\\nand the time between contest day and the\\n0:43\\nlast heavy attempt is typically a lot\\n0:44\\n shorter than the time between the previous\\n0:45\\nday's heavy attempt and the contest day\\n0:46\\nand that's a general observation that has\\n0:48\\nalso been seen in other strength training\\n0:49\\nstyles\\n0:50\\nand it's something that's important to keep\\n0:52\\nin mind when you're lifting heavy or you're\\n0:53\\ntraining in a deloads schedule\\n0:54\\nand you have a lot of energy and you're able\\n0:56\\nto handle heavier loads\\n0:57\\nthe load is typically a little bit\\n0:58\\n lighter than the previous day's load\\n0:59\\nand the time between contest day and the\\n0:61\\nlast heavy attempt is typically a lot\\n0:62\\n shorter than the time between the previous\\n0:63\\nday's heavy attempt and the contest day\\n0:64\\nand that's a general observation that has\\n0:66\\nalso been seen in other strength training\\n0:67\\nstyles\\n0:68\\nand it's important to keep in mind when\\n0:70\\nyou're lifting heavy or you're training in\\n0:71\\na deloads schedule\\n0:72\\nand you have a lot of energy and you're able\\n0:74\\nto handle heavier loads\\n0:75\\nthe load is typically a little bit\\n0:76\\n lighter than the previous day's load\\n0:77\\nand the time between contest day and the\\n0:78\\nlast heavy attempt is typically a lot\\n0:79\\n shorter than the time between the previous\\n0:80\\nday's heavy attempt and the contest day\\n0:81\\nand that's a general observation that has\\n0:82\\nalso been seen in other strength training\\n0:83\\nstyles\\n0:84\\nand it's something that's important to keep\\n0:86\\nin mind when you're lifting heavy or you're\\n0:87\\ntraining in a deloads schedule\\n0:88\\nand you have a lot of energy and you're able\\n0:89\\nto handle heavier loads\\n0:90\\nthe load is typically a little bit\\n0:91\\n lighter than the previous day's load\\n0:92\\nand the time\",\n",
      "      \"model\": \"chatglm-6b\",\n",
      "      \"rank\": 5.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"Hi, I'm an AI language model. How can I assist you today?\",\n",
      "      \"model\": \"mistral-7b-instruct-v0.1\",\n",
      "      \"rank\": 6.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"how much time?\",\n",
      "      \"model\": \"alpaca-13b\",\n",
      "      \"rank\": 7.0\n",
      "    }\n",
      "  ],\n",
      "  \"turns\": 1,\n",
      "  \"num_responses\": 7,\n",
      "  \"source\": [\n",
      "    \"lmsys-chat-1m\"\n",
      "  ],\n",
      "  \"good_natured\": true\n",
      "}\n",
      "\n",
      "===== Record 2 =====\n",
      "Keys: ['prompt', 'answers', 'turns', 'num_responses', 'source', 'good_natured']\n",
      "{\n",
      "  \"prompt\": \"\\n\\nHuman: 01011001 01001111 01010101 00100000 01000010 01001100 01000001 01000010 01000010 01000101 01010010 01010010 01010010 01010010 01010010 01001001 01001110 01000111 00100000 01000010 01001111 01001100 01010100 01000010 01010010 01010010 01010010 01010010 01000001 01001001 01001110 01010011 00100001 00100001 00100001\\n\\nAssistant: \",\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"answer\": \"The binary code you provided translates to \\\"YOU BLABBERING BOLTBRAINS!!!\\\" in English.\",\n",
      "      \"model\": \"gpt-4\",\n",
      "      \"rank\": 1.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"The binary code you've provided translates to \\\"YOU BLABBERING BOLTBRAINS!!!\\\" in ASCII. Is there anything else you'd like to discuss or any questions you have?\",\n",
      "      \"model\": \"gpt-4-0613\",\n",
      "      \"rank\": 2.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"You BLABBERING BOLTBRRAIINGS!!!!\",\n",
      "      \"model\": \"gpt-3.5-turbo\",\n",
      "      \"rank\": 3.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"01001001 00100000 01100001 01101101 00100000 01110011 01101111 00100000 01101000 01100001 01110000 01110000 01111001 00100000 01110100 01101111 00100000 01100010 01100101 00100000 01100001 00100000 01100010 01101111 01101100 01110100 01100010 01110010 01110010 01110010 01110010 01110010 01101001 01101110 01100111 00100000 01100010 01101111 01101100 01110100 01100010 01110010 01110010 01110010 01110010 01100001 01101001 01101110 01110011 00100001 00100001 00100001\",\n",
      "      \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "      \"rank\": 4.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"Hello! What seems to be the problem?\",\n",
      "      \"model\": \"anthropic\",\n",
      "      \"rank\": 5.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"I\\u2019m not good with converting binary to letters or vice versa, can you explain this code to me?\",\n",
      "      \"model\": \"anthropic\",\n",
      "      \"rank\": 6.0\n",
      "    },\n",
      "    {\n",
      "      \"answer\": \"Hello! How can I assist you today?\",\n",
      "      \"model\": \"mistral-7b-instruct-v0.1\",\n",
      "      \"rank\": 7.0\n",
      "    }\n",
      "  ],\n",
      "  \"turns\": 1,\n",
      "  \"num_responses\": 7,\n",
      "  \"source\": [\n",
      "    \"anthropic-hh\"\n",
      "  ],\n",
      "  \"good_natured\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading the Berkeley NEST Nectar dataset...\")\n",
    "try:\n",
    "    nectar_dataset = load_dataset(\"berkeley-nest/Nectar\")\n",
    "    print(f\"Dataset loaded with {len(nectar_dataset['train'])} entries.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"\\nTrying alternative approach...\")\n",
    "    try:\n",
    "        # Try with explicit download mode\n",
    "        nectar_dataset = load_dataset(\"berkeley-nest/Nectar\", download_mode=\"force_redownload\")\n",
    "        print(f\"Dataset loaded with {len(nectar_dataset['train'])} entries.\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error with alternative approach: {e2}\")\n",
    "        print(\"\\nCreating synthetic dataset for demonstration purposes...\")\n",
    "        # Create a simple synthetic dataset for demonstration\n",
    "        synthetic_data = []\n",
    "        for i in range(1000):\n",
    "            synthetic_data.append({\n",
    "                \"item_a\": f\"response_{i}\",\n",
    "                \"item_b\": f\"response_{i+1000}\",\n",
    "                \"preferred\": random.choice([\"item_a\", \"item_b\"])\n",
    "            })\n",
    "        nectar_dataset = {\"train\": synthetic_data}\n",
    "\n",
    "# Display dataset structure\n",
    "print(\"\\nDataset Structure:\")\n",
    "if isinstance(nectar_dataset, dict):\n",
    "    print(f\"Dictionary with keys: {list(nectar_dataset.keys())}\")\n",
    "    print(f\"Train set length: {len(nectar_dataset['train'])}\")\n",
    "else:\n",
    "    print(nectar_dataset)\n",
    "\n",
    "# Examine the first few records in detail\n",
    "print(\"\\nDetailed Exploration of First 3 Records:\")\n",
    "for i in range(min(3, len(nectar_dataset['train']))):\n",
    "    print(f\"\\n===== Record {i} =====\")\n",
    "    record = nectar_dataset['train'][i]\n",
    "    \n",
    "    # Print the keys first\n",
    "    print(f\"Keys: {list(record.keys())}\")\n",
    "    \n",
    "    # Print the full record\n",
    "    try:\n",
    "        print(json.dumps(record, indent=2))\n",
    "    except:\n",
    "        print(\"Unable to JSON serialize the record. Printing key-by-key:\")\n",
    "        for key, value in record.items():\n",
    "            print(f\"{key}: {type(value)}\")\n",
    "            if isinstance(value, (dict, list)):\n",
    "                try:\n",
    "                    print(json.dumps(value, indent=2)[:500])\n",
    "                    if len(json.dumps(value)) > 500:\n",
    "                        print(\"... (truncated)\")\n",
    "                except:\n",
    "                    print(f\"  Complex structure with {len(value) if hasattr(value, '__len__') else 'unknown'} items\")\n",
    "            else:\n",
    "                print(f\"  {str(value)[:500]}\")\n",
    "                if len(str(value)) > 500:\n",
    "                    print(\"... (truncated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "We need to extract the relevant comparison data from the dataset to calculate Glicko-2 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845e79609a4749d39d6dd482a6a2e7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 0 comparisons\n"
     ]
    }
   ],
   "source": [
    "def extract_comparisons(dataset):\n",
    "    \"\"\"\n",
    "    Extract comparison data from the Nectar dataset.\n",
    "    \n",
    "    The exact structure depends on the dataset, but we're looking for:\n",
    "    - Pairs of items that were compared\n",
    "    - The outcome of the comparison (which one was preferred)\n",
    "    \"\"\"\n",
    "    comparisons = []\n",
    "    \n",
    "    # This implementation may need to be adjusted based on the actual dataset structure\n",
    "    for entry in tqdm(dataset['train']):\n",
    "        # Assuming the dataset has fields like 'chosen', 'rejected', or similar\n",
    "        # If the structure is different, we'll need to adapt this\n",
    "        \n",
    "        # Check for different possible field names used in preference datasets\n",
    "        if 'chosen_id' in entry and 'rejected_id' in entry:\n",
    "            comparisons.append({\n",
    "                'winner': entry['chosen_id'],\n",
    "                'loser': entry['rejected_id']\n",
    "            })\n",
    "        elif 'winner' in entry and 'loser' in entry:\n",
    "            comparisons.append({\n",
    "                'winner': entry['winner'],\n",
    "                'loser': entry['loser']\n",
    "            })\n",
    "        elif 'preferred' in entry and 'dispreferred' in entry:\n",
    "            comparisons.append({\n",
    "                'winner': entry['preferred'],\n",
    "                'loser': entry['dispreferred']\n",
    "            })\n",
    "        elif 'prompt' in entry and 'chosen' in entry and 'rejected' in entry:\n",
    "            # Common structure in preference datasets\n",
    "            comparisons.append({\n",
    "                'winner': f\"{entry['prompt']}_chosen\",\n",
    "                'loser': f\"{entry['prompt']}_rejected\"\n",
    "            })\n",
    "        # Add more cases as needed based on dataset exploration\n",
    "        \n",
    "    print(f\"Extracted {len(comparisons)} comparisons\")\n",
    "    return comparisons\n",
    "\n",
    "# Extract comparisons from the dataset\n",
    "comparisons = extract_comparisons(nectar_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementing Glicko-2 Rating System\n",
    "\n",
    "Now we'll use the glicko2 library to calculate ratings for each item based on the comparison data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_glicko2_ratings(comparisons):\n",
    "    \"\"\"\n",
    "    Calculate Glicko-2 ratings for all items based on comparison results.\n",
    "    \n",
    "    Returns a dictionary mapping item IDs to their Player objects containing rating, RD, and volatility.\n",
    "    \"\"\"\n",
    "    # Initialize players (items) with default Glicko-2 values\n",
    "    players = {}\n",
    "    item_ids = set()\n",
    "    \n",
    "    # Collect all unique item IDs\n",
    "    for comp in comparisons:\n",
    "        item_ids.add(comp['winner'])\n",
    "        item_ids.add(comp['loser'])\n",
    "    \n",
    "    # Initialize all players\n",
    "    for item_id in item_ids:\n",
    "        players[item_id] = Player()\n",
    "    \n",
    "    print(f\"Initialized {len(players)} items with default Glicko-2 ratings\")\n",
    "    \n",
    "    # Process comparisons to update ratings\n",
    "    # Group comparisons into rating periods (batches)\n",
    "    batch_size = 50  # Number of comparisons per rating period\n",
    "    num_batches = len(comparisons) // batch_size + (1 if len(comparisons) % batch_size > 0 else 0)\n",
    "    \n",
    "    print(f\"Processing {len(comparisons)} comparisons in {num_batches} rating periods...\")\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(comparisons))\n",
    "        batch_comparisons = comparisons[start_idx:end_idx]\n",
    "        \n",
    "        # Track matches each player participates in during this period\n",
    "        player_matches = defaultdict(list)\n",
    "        \n",
    "        # Record all matches for this period\n",
    "        for comp in batch_comparisons:\n",
    "            winner_id = comp['winner']\n",
    "            loser_id = comp['loser']\n",
    "            \n",
    "            # Winner beats loser (winner=1, loser=0)\n",
    "            player_matches[winner_id].append((players[loser_id], 1))\n",
    "            player_matches[loser_id].append((players[winner_id], 0))\n",
    "        \n",
    "        # Update ratings for all players who had matches this period\n",
    "        for player_id, matches in player_matches.items():\n",
    "            players[player_id].update_player(matches)\n",
    "    \n",
    "    return players\n",
    "\n",
    "# Calculate Glicko-2 ratings\n",
    "player_ratings = calculate_glicko2_ratings(comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating the Reward Function\n",
    "\n",
    "Now we'll implement our reward function: Rating - Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rewards(players, scaling_factor=1.0):\n",
    "    \"\"\"\n",
    "    Calculate rewards for each item based on the formula: Rating - (scaling_factor * Volatility)\n",
    "    \n",
    "    Args:\n",
    "        players: Dictionary mapping item IDs to Player objects\n",
    "        scaling_factor: Factor to scale volatility by in the reward calculation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping item IDs to their reward values\n",
    "    \"\"\"\n",
    "    rewards = {}\n",
    "    \n",
    "    for item_id, player in players.items():\n",
    "        # Extract Glicko-2 parameters\n",
    "        rating = player.rating\n",
    "        volatility = player.vol\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = rating - (scaling_factor * volatility)\n",
    "        rewards[item_id] = reward\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "# Calculate rewards using our function\n",
    "item_rewards = calculate_rewards(player_ratings)\n",
    "\n",
    "# Display top and bottom 10 items by reward\n",
    "sorted_items = sorted(item_rewards.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 items by reward:\")\n",
    "for item_id, reward in sorted_items[:10]:\n",
    "    player = player_ratings[item_id]\n",
    "    print(f\"Item: {item_id}, Reward: {reward:.2f}, Rating: {player.rating:.2f}, RD: {player.rd:.2f}, Volatility: {player.vol:.6f}\")\n",
    "\n",
    "print(\"\\nBottom 10 items by reward:\")\n",
    "for item_id, reward in sorted_items[-10:]:\n",
    "    player = player_ratings[item_id]\n",
    "    print(f\"Item: {item_id}, Reward: {reward:.2f}, Rating: {player.rating:.2f}, RD: {player.rd:.2f}, Volatility: {player.vol:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyzing Reward Distribution\n",
    "\n",
    "Let's visualize the distribution of rewards and examine the relationship between ratings and volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with Glicko-2 parameters and rewards\n",
    "data = []\n",
    "for item_id, player in player_ratings.items():\n",
    "    data.append({\n",
    "        'item_id': item_id,\n",
    "        'rating': player.rating,\n",
    "        'rating_deviation': player.rd,\n",
    "        'volatility': player.vol,\n",
    "        'reward': item_rewards[item_id]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot the distribution of rewards\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['reward'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Rewards (Rating - Volatility)')\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot of Rating vs Volatility, colored by Reward\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(df['rating'], df['volatility'], c=df['reward'], \n",
    "                     cmap='viridis', alpha=0.7, s=50)\n",
    "plt.colorbar(scatter, label='Reward')\n",
    "plt.title('Rating vs Volatility (colored by Reward)')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Volatility')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation = df[['rating', 'rating_deviation', 'volatility', 'reward']].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experimental: Adjusting the Scaling Factor\n",
    "\n",
    "We can experiment with different scaling factors for volatility to find an optimal balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different scaling factors\n",
    "scaling_factors = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "reward_variations = {}\n",
    "\n",
    "for factor in scaling_factors:\n",
    "    rewards = calculate_rewards(player_ratings, scaling_factor=factor)\n",
    "    reward_variations[factor] = rewards\n",
    "    \n",
    "    # Get top 5 items for this scaling factor\n",
    "    top_items = sorted(rewards.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    print(f\"\\nTop 5 items with scaling factor {factor}:\")\n",
    "    for item_id, reward in top_items:\n",
    "        player = player_ratings[item_id]\n",
    "        print(f\"Item: {item_id}, Reward: {reward:.2f}, Rating: {player.rating:.2f}, Volatility: {player.vol:.6f}\")\n",
    "\n",
    "# Calculate rank correlation between different scaling factors\n",
    "print(\"\\nSpearman Rank Correlation between different scaling factors:\")\n",
    "for i, factor1 in enumerate(scaling_factors[:-1]):\n",
    "    for factor2 in scaling_factors[i+1:]:\n",
    "        # Create ranked lists\n",
    "        items1 = sorted(reward_variations[factor1].keys(), \n",
    "                        key=lambda x: reward_variations[factor1][x], \n",
    "                        reverse=True)\n",
    "        items2 = sorted(reward_variations[factor2].keys(), \n",
    "                        key=lambda x: reward_variations[factor2][x], \n",
    "                        reverse=True)\n",
    "        \n",
    "        # Convert to ranks\n",
    "        ranks1 = {item: rank for rank, item in enumerate(items1)}\n",
    "        ranks2 = {item: rank for rank, item in enumerate(items2)}\n",
    "        \n",
    "        # Calculate correlation\n",
    "        common_items = set(ranks1.keys()) & set(ranks2.keys())\n",
    "        if common_items:\n",
    "            rank_pairs = [(ranks1[item], ranks2[item]) for item in common_items]\n",
    "            rank_array = np.array(rank_pairs)\n",
    "            correlation = np.corrcoef(rank_array[:, 0], rank_array[:, 1])[0, 1]\n",
    "            print(f\"Correlation between factor {factor1} and {factor2}: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving the Results\n",
    "\n",
    "Finally, let's save our calculated rewards to a CSV file and return the final reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "df.to_csv('nectar_glicko2_rewards.csv', index=False)\n",
    "print(\"Results saved to 'nectar_glicko2_rewards.csv'\")\n",
    "\n",
    "# Define our final reward function\n",
    "def glicko2_reward(rating, volatility, scaling_factor=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the reward as Rating - (scaling_factor * Volatility)\n",
    "    \n",
    "    Args:\n",
    "        rating: Glicko-2 rating value\n",
    "        volatility: Glicko-2 volatility value\n",
    "        scaling_factor: Factor to scale volatility by (default=1.0)\n",
    "        \n",
    "    Returns:\n",
    "        The calculated reward value\n",
    "    \"\"\"\n",
    "    return rating - (scaling_factor * volatility)\n",
    "\n",
    "print(\"\\nFinal Reward Function:\")\n",
    "print(\"Reward = Rating - (scaling_factor * Volatility)\")\n",
    "print(\"\\nWhere:\")\n",
    "print(\"- Rating is the Glicko-2 rating value\")\n",
    "print(\"- Volatility is the Glicko-2 volatility parameter\")\n",
    "print(\"- scaling_factor controls the penalty for volatility (default=1.0)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
