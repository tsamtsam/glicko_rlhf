{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glicko-2 Reward Function for Nectar Dataset\n",
    "\n",
    "This notebook implements a reward function based on Glicko-2 ratings for the Berkeley NEST Nectar dataset. The reward function is defined as:\n",
    "\n",
    "```\n",
    "Reward = Glicko-2 Rating - Rating Volatility\n",
    "```\n",
    "\n",
    "This rewards items with high ratings while penalizing those with high volatility (inconsistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, IterableDataset, concatenate_datasets, Dataset # Make sure IterableDataset is imported if using streaming\n",
    "from glicko2 import Player\n",
    "import re\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_dataset(\"Columbia-NLP/DPO-tldr-summarisation-preferences\")\n",
    "train = d['train']\n",
    "val = d['validation']\n",
    "test = d['test']\n",
    "dataset = train.add_column(\"sub_reddit\", [x['subreddit'] for x in train['other_info']])\n",
    "dataset_test = val.add_column(\"sub_reddit\", [x['subreddit'] for x in val['other_info']])\n",
    "dataset_eval = test.add_column(\"sub_reddit\", [x['subreddit'] for x in test['other_info']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AskReddit', 'tifu', 'relationships', 'dating_advice', 'Advice',\n",
       "       'jobs', 'cats', 'travel', 'personalfinance', 'relationship_advice',\n",
       "       'askwomenadvice', 'Pets', 'loseit', 'Dogtraining', 'Cooking',\n",
       "       'legaladvice', 'running', 'offmychest', 'Parenting', 'dogs',\n",
       "       'BreakUps', 'self', 'weddingplanning', 'AskDocs', 'needadvice',\n",
       "       'books', 'GetMotivated', 'pettyrevenge', 'college'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sub_reddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sr = ['AskDocs', 'legaladvice', 'Advice', 'askwomenadvice', 'AskReddit', 'needadvice', 'relationship_advice', 'dating_advice' ]\n",
    "test_sr = ['running','Cooking']\n",
    "train_df = df.loc[ df['sub_reddit'].isin(train_sr)]\n",
    "test_df = df.loc[ df['sub_reddit'].isin(test_sr)]\n",
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_chosen</th>\n",
       "      <th>score_rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27000.0</td>\n",
       "      <td>27000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score_chosen  score_rejected\n",
       "count       27000.0         27000.0\n",
       "mean           10.0             1.0\n",
       "std             0.0             0.0\n",
       "min            10.0             1.0\n",
       "25%            10.0             1.0\n",
       "50%            10.0             1.0\n",
       "75%            10.0             1.0\n",
       "max            10.0             1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_chosen</th>\n",
       "      <th>score_rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>524.0</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score_chosen  score_rejected\n",
       "count         524.0           524.0\n",
       "mean           10.0             1.0\n",
       "std             0.0             0.0\n",
       "min            10.0             1.0\n",
       "25%            10.0             1.0\n",
       "50%            10.0             1.0\n",
       "75%            10.0             1.0\n",
       "max            10.0             1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an AI assistant good at summarizing reddit post. Your task is to summarize the following post from subreddit r/running without including unimportant or irrelevant details.\\nA good summary is both precise and concise.\\n\\nPost:\\nI\\'m totally stoked! I knew I\\'d probably be taking in some extra calories over the holiday so I talked myself into it. Prior to this my farthest distance was 10 miles. It was totally unplanned and was a great example of overcoming that voice in your head that says \"Can\\'t\". Here\\'s how the conversation went:\\n\\nWife as I\\'m walking out the door: How far are you running?\\n\\nPositive Me: At least 5 miles\\n\\nWife: Cool.\\n\\n(After a quick stretch, I start running)\\n\\nNegative me (.25 miles): Man, I\\'m not feeling it today. I think I\\'ll just run 2-3 and call it a day.\\n\\nPositive me: Seriously? Just for your whining, now you\\'re running AT LEAST 8 miles.\\n\\nNegative me: What? We\\'ll see.\\n\\nPositive me (.5 miles): Nope. No argument. Man up.\\n\\n...(running continues)\\n\\nPositive me (5 miles): Man, this feels great! Aren\\'t you glad you didn\\'t quit?\\n\\nNegative me: Ya, I guess so. Still, this is pretty far. Want to call it a day?\\n\\nPositive me: Don\\'t you ever learn? Now we\\'re going to run a half marathon?\\n\\nNegative me: WHAT?! We\\'ve never run that far.\\n\\nPositive me: Well, what would you rather be doing? Sitting on the couch, drinking, and watching Netflix? Let\\'s do this!\\n\\n...(running continues)\\n\\nNegative me (11 miles): Well, this has been fun but we\\'ve been running for over an hour and a half now...and this is farther than we\\'ve ever run. Maybe call it a day?\\n\\nPositive me: Ya, exactly, we\\'ve been running for over an hour and a half and only have around 20 minutes left to accomplish something we\\'ve never done before. Are you crazy?\\n\\nMe: You know what, you\\'re right. LET\\'S DO THIS.\\n\\nSummary:'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['prompt'].iloc[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'other_info', 'sub_reddit', '__index_level_0__'],\n",
       "    num_rows: 27000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2i = {}\n",
    "i2p = {}\n",
    "a2i = {}\n",
    "i2a = {}\n",
    "p = 0 \n",
    "a = 0 \n",
    "for row in dataset:\n",
    "    if row['prompt'] not in p2i:\n",
    "        p2i[row['prompt']] = p\n",
    "        i2p[p] = row['prompt']\n",
    "        p+=1\n",
    "    if row['chosen'][1]['content'] not in a2i:\n",
    "        a2i[row['chosen'][1]['content']] = a\n",
    "        i2a[a] = row['chosen'][1]['content']\n",
    "        a += 1\n",
    "    if row['rejected'][1]['content'] not in a2i:\n",
    "        a2i[row['rejected'][1]['content']] = a\n",
    "        i2a[a] = row['rejected'][1]['content']\n",
    "        a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing player storage...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Initialize Player Storage ---\n",
    "print(\"Initializing player storage...\")\n",
    "# Use the Player class defined above\n",
    "players = {} # Dictionary to store author_id -> Player object instance\n",
    "all_known_players = set() # Keep track of all players ever encountered\n",
    "\n",
    "def get_player(author_id):\n",
    "    \"\"\"Gets or creates a Player object for a valid author ID.\"\"\"\n",
    "    # Check specifically against None and handle empty strings if necessary\n",
    "    if author_id is not None and author_id.strip() != '' and author_id.lower() != '[deleted]':\n",
    "        if author_id not in players:\n",
    "            players[author_id] = Player() # Use the provided Player class\n",
    "            # print(f\"Created player: {author_id}\") # Optional: for debugging\n",
    "        all_known_players.add(author_id) # Track all valid players encountered\n",
    "        return players.get(author_id)\n",
    "    return None # Return None for invalid authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing matches and grouping by period...\n",
      "Gathered data for 20000/27000 rows...\n",
      "\n",
      "--- Data Gathering Summary ---\n",
      "Total rows processed: 27000\n",
      "Matches skipped (same author): 6\n",
      "Matches skipped (deleted/invalid author): 0\n",
      "Matches skipped (data fetch error): 0\n",
      "Total unique valid authors encountered: 18090\n",
      "Number of rating periods found: 1\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Process Matches and Group by Period ---\n",
    "print(\"Processing matches and grouping by period...\")\n",
    "matches_by_period = defaultdict(lambda: defaultdict(lambda: {'ratings': [], 'rds': [], 'outcomes': []}))\n",
    "processed_count = 0\n",
    "# max_rows_to_process = 100000 # Optional: Limit rows for testing even without streaming\n",
    "skipped_same_author = 0\n",
    "skipped_deleted = 0\n",
    "skipped_fetch_error = 0\n",
    "max_rows_to_process = 5000\n",
    "# Now iterate directly over the loaded dataset (which acts like a list/dict)\n",
    "try:\n",
    "    for i, row in enumerate(dataset):\n",
    "        processed_count += 1\n",
    "        # if processed_count > max_rows_to_process: # Apply optional limit if defined\n",
    "        #      print(f\"Reached processing limit of {max_rows_to_process} rows.\")\n",
    "        #      break\n",
    "        \n",
    "        # Extract data\n",
    "        p_ind = p2i[row.get('prompt')]\n",
    "        # Player j won\n",
    "        author_j = str((p_ind, a2i[row.get('chosen')[1]['content']]))\n",
    "        author_k = str((p_ind, a2i[row.get('rejected')[1]['content']]))\n",
    "\n",
    "        if author_j is None or author_k is None:\n",
    "            skipped_fetch_error += 1\n",
    "            continue\n",
    "        if author_j == author_k:\n",
    "            skipped_same_author += 1\n",
    "            continue\n",
    "\n",
    "        player_j = get_player(author_j)\n",
    "        player_k = get_player(author_k)\n",
    "\n",
    "        if player_j is None or player_k is None:\n",
    "            skipped_deleted += 1\n",
    "            continue\n",
    "        period = '0'\n",
    "        rating_j_current = player_j.rating\n",
    "        rd_j_current = player_j.rd\n",
    "        rating_k_current = player_k.rating\n",
    "        rd_k_current = player_k.rd\n",
    "\n",
    "        outcome_for_j = 1.0\n",
    "        outcome_for_k = 0.0\n",
    "\n",
    "        matches_by_period[period][author_j]['ratings'].append(rating_k_current)\n",
    "        matches_by_period[period][author_j]['rds'].append(rd_k_current)\n",
    "        matches_by_period[period][author_j]['outcomes'].append(outcome_for_j)\n",
    "\n",
    "        matches_by_period[period][author_k]['ratings'].append(rating_j_current)\n",
    "        matches_by_period[period][author_k]['rds'].append(rd_j_current)\n",
    "        matches_by_period[period][author_k]['outcomes'].append(outcome_for_k)\n",
    "\n",
    "        if processed_count % 20000 == 0: # Adjust print frequency as needed\n",
    "            print(f\"Gathered data for {processed_count}/{len(dataset)} rows...\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during data iteration at row {processed_count}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- Data Gathering Summary ---\")\n",
    "# ... [Summary print statements remain the same] ...\n",
    "print(f\"Total rows processed: {processed_count}\")\n",
    "print(f\"Matches skipped (same author): {skipped_same_author}\")\n",
    "print(f\"Matches skipped (deleted/invalid author): {skipped_deleted}\")\n",
    "print(f\"Matches skipped (data fetch error): {skipped_fetch_error}\")\n",
    "print(f\"Total unique valid authors encountered: {len(all_known_players)}\")\n",
    "print(f\"Number of rating periods found: {len(matches_by_period)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating ratings period by period...\n",
      "Processing period: 0\n",
      "-> Completed updates for 18090 active players. Applied inactivity update for 0 players.\n",
      "Rating updates complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Run Glicko-2 Updates Period by Period ---\n",
    "print(\"\\nUpdating ratings period by period...\")\n",
    "# ... [Rating update loop remains the same as previous response] ...\n",
    "sorted_periods = sorted(matches_by_period.keys())\n",
    "\n",
    "for period in sorted_periods:\n",
    "    print(f\"Processing period: {period}\")\n",
    "    players_in_period = set(matches_by_period[period].keys())\n",
    "\n",
    "    # Identify players who *didn't* compete in this period but existed before\n",
    "    inactive_players_in_period = all_known_players - players_in_period\n",
    "\n",
    "    # Apply Step 6: Update RD for inactive players\n",
    "    inactive_update_count = 0\n",
    "    for author_id in inactive_players_in_period:\n",
    "        player = players.get(author_id)\n",
    "        if player: # Should always exist if in all_known_players\n",
    "             try:\n",
    "                 player.did_not_compete()\n",
    "                 inactive_update_count += 1\n",
    "             except Exception as e:\n",
    "                 print(f\"Error calling did_not_compete for {author_id} in period {period}: {e}\")\n",
    "\n",
    "    # Apply Steps 3-5: Update rating, RD, vol for active players\n",
    "    updates_count = 0\n",
    "    for author_id in players_in_period:\n",
    "        player = players.get(author_id)\n",
    "        if not player: continue # Should not happen if key exists, but safe check\n",
    "\n",
    "        period_data = matches_by_period[period][author_id]\n",
    "        opponent_ratings = period_data['ratings']\n",
    "        opponent_rds = period_data['rds']\n",
    "        outcomes = period_data['outcomes']\n",
    "\n",
    "        # Ensure we have opponents before calling update\n",
    "        if opponent_ratings:\n",
    "            try:\n",
    "                player.update_player(opponent_ratings, opponent_rds, outcomes)\n",
    "                updates_count += 1\n",
    "            except OverflowError:\n",
    "                 print(f\"OverflowError encountered updating player {author_id} in period {period}. Skipping update.\")\n",
    "                 # This can happen with extreme rating differences or RDs. Might indicate need for parameter tuning or data cleaning.\n",
    "                 # Consider logging player state: player.rating, player.rd, player.vol and opponent data\n",
    "            except FloatingPointError as fpe:\n",
    "                print(f\"FloatingPointError encountered updating player {author_id} in period {period}: {fpe}. Skipping update.\")\n",
    "            except Exception as e:\n",
    "                 print(f\"Error updating player {author_id} in period {period}: {e}\")\n",
    "\n",
    "\n",
    "    print(f\"-> Completed updates for {updates_count} active players. Applied inactivity update for {inactive_update_count} players.\")\n",
    "\n",
    "\n",
    "print(\"Rating updates complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Glicko-2 Ratings for Authors ---\n",
      "Displaying top 20 and bottom 10 authors:\n",
      "              author       rating  deviation (RD)  volatility\n",
      "10493  (2591, 10490)  1994.016832       77.239280    0.062963\n",
      "14720  (3604, 14715)  1992.220354       79.937647    0.062522\n",
      "4312    (1075, 4312)  1985.889097       88.796359    0.061555\n",
      "5736    (1426, 5736)  1985.889097       88.796359    0.061555\n",
      "10523  (2598, 10520)  1983.814762       91.512517    0.061355\n",
      "11984  (2952, 11980)  1978.783432       97.787750    0.061001\n",
      "3898     (971, 3898)  1978.783432       97.787750    0.061001\n",
      "3896     (971, 3896)  1978.783432       97.787750    0.061001\n",
      "12833  (3156, 12829)  1975.691675      101.451559    0.060846\n",
      "12835  (3156, 12831)  1975.691675      101.451559    0.060846\n",
      "7093    (1763, 7093)  1972.088889      105.560665    0.060706\n",
      "10495  (2591, 10492)  1972.083424       76.398758    0.062802\n",
      "888       (222, 888)  1968.805377       79.006998    0.062377\n",
      "11598  (2856, 11594)  1963.654207       82.940118    0.061878\n",
      "12196  (3003, 12192)  1962.743042      115.540772    0.060464\n",
      "14426  (3534, 14421)  1962.743042      115.540772    0.060464\n",
      "2885     (721, 2885)  1962.197862       84.018723    0.061764\n",
      "7049    (1752, 7049)  1959.043798       86.308515    0.061548\n",
      "9564    (2364, 9562)  1956.529573      121.723950    0.060363\n",
      "3960     (987, 3960)  1956.529573      121.723950    0.060363\n",
      "...\n",
      "              author       rating  deviation (RD)  volatility\n",
      "13551  (3324, 13546)  1016.185238       91.512517    0.061355\n",
      "10522  (2598, 10519)  1016.185238       91.512517    0.061355\n",
      "9627    (2378, 9625)  1016.185238       91.512517    0.061355\n",
      "12482  (3069, 12478)  1012.265765       86.308532    0.061770\n",
      "195        (48, 195)  1010.613823       84.018741    0.062003\n",
      "5310    (1321, 5310)  1009.126240       81.902033    0.062254\n",
      "14723  (3604, 14718)  1006.554902       78.108149    0.062811\n",
      "10496  (2591, 10493)  1005.983168       77.239280    0.062963\n",
      "1809     (453, 1809)  1000.006611       67.491064    0.065738\n",
      "1846     (462, 1846)   996.753739       61.541390    0.069525\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Display Results ---\n",
    "print(\"\\n--- Final Glicko-2 Ratings for Authors ---\")\n",
    "# ... [Result display remains the same as previous response] ...\n",
    "author_ratings = []\n",
    "skipped_final_rating = 0\n",
    "for author_id, player in players.items():\n",
    "    try:\n",
    "        # Add check for NaN/Inf before appending\n",
    "        rating_val = player.rating\n",
    "        rd_val = player.rd\n",
    "        vol_val = player.vol\n",
    "        if not (math.isfinite(rating_val) and math.isfinite(rd_val) and math.isfinite(vol_val)):\n",
    "            print(f\"Warning: Non-finite values for player {author_id}. Rating={rating_val}, RD={rd_val}, Vol={vol_val}. Skipping.\")\n",
    "            skipped_final_rating += 1\n",
    "            continue\n",
    "\n",
    "        author_ratings.append({\n",
    "            \"author\": author_id,\n",
    "            \"rating\": rating_val, # Uses the property getter\n",
    "            \"deviation (RD)\": rd_val, # Uses the property getter\n",
    "            \"volatility\": vol_val\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving final rating for {author_id}: {e}\")\n",
    "        skipped_final_rating += 1\n",
    "\n",
    "\n",
    "if skipped_final_rating > 0:\n",
    "    print(f\"\\nNote: Skipped retrieving final ratings for {skipped_final_rating} authors due to errors or non-finite values.\")\n",
    "\n",
    "# Sort by rating descending for readability\n",
    "results_df = pd.DataFrame(author_ratings)\n",
    "\n",
    "if not results_df.empty:\n",
    "    # Ensure columns are numeric before sorting\n",
    "    results_df['rating'] = pd.to_numeric(results_df['rating'], errors='coerce')\n",
    "    results_df['deviation (RD)'] = pd.to_numeric(results_df['deviation (RD)'], errors='coerce')\n",
    "    results_df['volatility'] = pd.to_numeric(results_df['volatility'], errors='coerce')\n",
    "    results_df.dropna(subset=['rating'], inplace=True) # Remove rows where rating became NaN\n",
    "\n",
    "if not results_df.empty:\n",
    "    results_df = results_df.sort_values(by=\"rating\", ascending=False)\n",
    "\n",
    "    # Display top N and bottom N for brevity, or the whole list\n",
    "    pd.set_option('display.max_rows', 100) # Show more rows if needed\n",
    "    print(f\"Displaying top {min(20, len(results_df))} and bottom {min(10, len(results_df))} authors:\")\n",
    "    print(results_df.head(20))\n",
    "    if len(results_df) > 30:\n",
    "        print(\"...\")\n",
    "        print(results_df.tail(10))\n",
    "    elif len(results_df) > 20:\n",
    "         print(\"...\") # Just indicate truncation if list is moderately long\n",
    "else:\n",
    "    print(\"No valid final ratings could be generated or displayed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing 18090 valid results...\n",
      "\n",
      "Displaying top 20 authors (incl. normalized scores):\n",
      "              author     rating  rating_norm  deviation (RD)  rd_norm  volatility  volatility_norm\n",
      "10493  (2591, 10490)  1994.0168       1.0000         77.2393   0.0686      0.0630           0.3168\n",
      "14720  (3604, 14715)  1992.2204       0.9982         79.9376   0.0804      0.0625           0.2709\n",
      "4312    (1075, 4312)  1985.8891       0.9918         88.7964   0.1191      0.0616           0.1701\n",
      "5736    (1426, 5736)  1985.8891       0.9918         88.7964   0.1191      0.0616           0.1701\n",
      "10523  (2598, 10520)  1983.8148       0.9898         91.5125   0.1310      0.0614           0.1493\n",
      "11984  (2952, 11980)  1978.7834       0.9847         97.7877   0.1584      0.0610           0.1125\n",
      "3898     (971, 3898)  1978.7834       0.9847         97.7877   0.1584      0.0610           0.1125\n",
      "3896     (971, 3896)  1978.7834       0.9847         97.7877   0.1584      0.0610           0.1125\n",
      "12833  (3156, 12829)  1975.6917       0.9816        101.4516   0.1745      0.0608           0.0964\n",
      "12835  (3156, 12831)  1975.6917       0.9816        101.4516   0.1745      0.0608           0.0964\n",
      "7093    (1763, 7093)  1972.0889       0.9780        105.5607   0.1924      0.0607           0.0817\n",
      "10495  (2591, 10492)  1972.0834       0.9780         76.3988   0.0649      0.0628           0.3000\n",
      "888       (222, 888)  1968.8054       0.9747         79.0070   0.0763      0.0624           0.2558\n",
      "11598  (2856, 11594)  1963.6542       0.9696         82.9401   0.0935      0.0619           0.2038\n",
      "12196  (3003, 12192)  1962.7430       0.9686        115.5408   0.2360      0.0605           0.0566\n",
      "14426  (3534, 14421)  1962.7430       0.9686        115.5408   0.2360      0.0605           0.0566\n",
      "2885     (721, 2885)  1962.1979       0.9681         84.0187   0.0983      0.0618           0.1919\n",
      "7049    (1752, 7049)  1959.0438       0.9649         86.3085   0.1083      0.0615           0.1695\n",
      "9564    (2364, 9562)  1956.5296       0.9624        121.7239   0.2631      0.0604           0.0461\n",
      "3960     (987, 3960)  1956.5296       0.9624        121.7239   0.2631      0.0604           0.0461\n",
      "...\n",
      "\n",
      "Displaying bottom 10 authors (incl. normalized scores):\n",
      "              author     rating  rating_norm  deviation (RD)  rd_norm  volatility  volatility_norm\n",
      "13551  (3324, 13546)  1016.1852       0.0195         91.5125   0.1310      0.0614           0.1493\n",
      "10522  (2598, 10519)  1016.1852       0.0195         91.5125   0.1310      0.0614           0.1493\n",
      "9627    (2378, 9625)  1016.1852       0.0195         91.5125   0.1310      0.0614           0.1493\n",
      "12482  (3069, 12478)  1012.2658       0.0156         86.3085   0.1083      0.0618           0.1926\n",
      "195        (48, 195)  1010.6138       0.0139         84.0187   0.0983      0.0620           0.2168\n",
      "5310    (1321, 5310)  1009.1262       0.0124         81.9020   0.0890      0.0623           0.2429\n",
      "14723  (3604, 14718)  1006.5549       0.0098         78.1081   0.0724      0.0628           0.3009\n",
      "10496  (2591, 10493)  1005.9832       0.0093         77.2393   0.0686      0.0630           0.3168\n",
      "1809     (453, 1809)  1000.0066       0.0033         67.4911   0.0260      0.0657           0.6057\n",
      "1846     (462, 1846)   996.7537       0.0000         61.5414   0.0000      0.0695           1.0000\n",
      "\n",
      "Results saved to author_ratings_normalized.csv\n",
      "\n",
      "Current time: 2025-06-01 22:22:29\n",
      "Total execution time: 5.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(author_ratings)\n",
    "\n",
    "# --- Normalization Step ---\n",
    "if not results_df.empty:\n",
    "    print(f\"\\nNormalizing {len(results_df)} valid results...\")\n",
    "    # Min-Max Normalization (scaling to [0, 1])\n",
    "\n",
    "    # Rating\n",
    "    r_min = results_df['rating'].min()\n",
    "    r_max = results_df['rating'].max()\n",
    "    if (r_max - r_min) != 0:\n",
    "        results_df['rating_norm'] = (results_df['rating'] - r_min) / (r_max - r_min)\n",
    "    else:\n",
    "        results_df['rating_norm'] = 0.5 # Assign midpoint if all values are the same\n",
    "\n",
    "    # Deviation (RD)\n",
    "    rd_min = results_df['deviation (RD)'].min()\n",
    "    rd_max = results_df['deviation (RD)'].max()\n",
    "    if (rd_max - rd_min) != 0:\n",
    "        results_df['rd_norm'] = (results_df['deviation (RD)'] - rd_min) / (rd_max - rd_min)\n",
    "    else:\n",
    "        results_df['rd_norm'] = 0.5\n",
    "\n",
    "    # Volatility\n",
    "    v_min = results_df['volatility'].min()\n",
    "    v_max = results_df['volatility'].max()\n",
    "    if (v_max - v_min) != 0:\n",
    "        results_df['volatility_norm'] = (results_df['volatility'] - v_min) / (v_max - v_min)\n",
    "    else:\n",
    "        results_df['volatility_norm'] = 0.5\n",
    "\n",
    "    # Sort by original rating\n",
    "    results_df = results_df.sort_values(by=\"rating\", ascending=False)\n",
    "\n",
    "    # Display selected columns including normalized ones\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    pd.set_option('display.width', 120) # Adjust width for better display\n",
    "    print(f\"\\nDisplaying top {min(20, len(results_df))} authors (incl. normalized scores):\")\n",
    "    # Select columns to display\n",
    "    display_cols = ['author', 'rating', 'rating_norm', 'deviation (RD)', 'rd_norm', 'volatility', 'volatility_norm']\n",
    "    print(results_df[display_cols].head(20).round(4)) # Round for display\n",
    "\n",
    "    if len(results_df) > 20:\n",
    "        print(\"...\")\n",
    "        print(f\"\\nDisplaying bottom {min(10, len(results_df))} authors (incl. normalized scores):\")\n",
    "        print(results_df[display_cols].tail(min(10, max(0, len(results_df)))).round(4))\n",
    "\n",
    "else:\n",
    "    print(\"No valid final ratings could be generated or displayed.\")\n",
    "df = results_df\n",
    "auth = df['author'].apply(lambda x: re.sub('[^A-Za-z0-9,]', '', str(x))).str.split(',')\n",
    "prompts = auth.apply(lambda x: i2p[int(x[0])])\n",
    "answers = auth.apply(lambda x: i2a[int(x[1])])\n",
    "df['question'] = prompts\n",
    "df['answer'] = answers\n",
    "\n",
    "# Optionally, save to CSV (including normalized columns)\n",
    "try:\n",
    "    if not df.empty:\n",
    "        df.to_csv(\"author_ratings_normalized.csv\", index=False, float_format='%.6f')\n",
    "        print(\"\\nResults saved to author_ratings_normalized.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving results to CSV: {e}\")\n",
    "end_time = time.time()\n",
    "print(f\"\\nCurrent time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries that map text to indices\n",
    "import pickle\n",
    "def save_dictionary(dictionary, filename):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a file using pickle.\n",
    "    \n",
    "    Args:\n",
    "        dictionary (dict): The dictionary to save\n",
    "        filename (str): The name of the file to save to\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "    print(f\"Dictionary saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to p2i\n",
      "Dictionary saved to i2a\n",
      "Dictionary saved to i2p\n",
      "Dictionary saved to a2i\n"
     ]
    }
   ],
   "source": [
    "save_dictionary(p2i, 'p2i')\n",
    "save_dictionary(i2a, 'i2a')\n",
    "save_dictionary(i2p, 'i2p')\n",
    "save_dictionary(a2i, 'a2i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>deviation (RD)</th>\n",
       "      <th>volatility</th>\n",
       "      <th>rating_norm</th>\n",
       "      <th>rd_norm</th>\n",
       "      <th>volatility_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18090.000000</td>\n",
       "      <td>18090.000000</td>\n",
       "      <td>18090.000000</td>\n",
       "      <td>18090.000000</td>\n",
       "      <td>18090.000000</td>\n",
       "      <td>18090.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1498.172204</td>\n",
       "      <td>240.171256</td>\n",
       "      <td>0.060013</td>\n",
       "      <td>0.502795</td>\n",
       "      <td>0.780802</td>\n",
       "      <td>0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>213.965473</td>\n",
       "      <td>26.584478</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.214553</td>\n",
       "      <td>0.116202</td>\n",
       "      <td>0.015639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>996.753739</td>\n",
       "      <td>61.541146</td>\n",
       "      <td>0.059920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1252.681917</td>\n",
       "      <td>227.735415</td>\n",
       "      <td>0.059997</td>\n",
       "      <td>0.256631</td>\n",
       "      <td>0.726444</td>\n",
       "      <td>0.007972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>253.404596</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.504627</td>\n",
       "      <td>0.838645</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1747.318083</td>\n",
       "      <td>253.404608</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.752624</td>\n",
       "      <td>0.838645</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1994.016832</td>\n",
       "      <td>290.318965</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating  deviation (RD)    volatility   rating_norm       rd_norm  volatility_norm\n",
       "count  18090.000000    18090.000000  18090.000000  18090.000000  18090.000000     18090.000000\n",
       "mean    1498.172204      240.171256      0.060013      0.502795      0.780802         0.009662\n",
       "std      213.965473       26.584478      0.000150      0.214553      0.116202         0.015639\n",
       "min      996.753739       61.541146      0.059920      0.000000      0.000000         0.000000\n",
       "25%     1252.681917      227.735415      0.059997      0.256631      0.726444         0.007972\n",
       "50%     1500.000000      253.404596      0.060003      0.504627      0.838645         0.008600\n",
       "75%     1747.318083      253.404608      0.060003      0.752624      0.838645         0.008600\n",
       "max     1994.016832      290.318965      0.069525      1.000000      1.000000         1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
