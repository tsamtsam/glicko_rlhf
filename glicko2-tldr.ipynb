{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glicko-2 Reward Function for Nectar Dataset\n",
    "\n",
    "This notebook implements a reward function based on Glicko-2 ratings for the Berkeley NEST Nectar dataset. The reward function is defined as:\n",
    "\n",
    "```\n",
    "Reward = Glicko-2 Rating - Rating Volatility\n",
    "```\n",
    "\n",
    "This rewards items with high ratings while penalizing those with high volatility (inconsistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, IterableDataset, concatenate_datasets # Make sure IterableDataset is imported if using streaming\n",
    "from glicko2 import Player\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_dataset(\"Columbia-NLP/DPO-tldr-summarisation-preferences\")\n",
    "train = d['train']\n",
    "val = d['validation']\n",
    "test = d['test']\n",
    "dataset = train.add_column(\"sub_reddit\", [x['subreddit'] for x in train['other_info']])\n",
    "dataset_test = val.add_column(\"sub_reddit\", [x['subreddit'] for x in val['other_info']])\n",
    "dataset_eval = test.add_column(\"sub_reddit\", [x['subreddit'] for x in test['other_info']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2i = {}\n",
    "i2p = {}\n",
    "a2i = {}\n",
    "i2a = {}\n",
    "p = 0 \n",
    "a = 0 \n",
    "for row in dataset:\n",
    "    if row['prompt'] not in p2i:\n",
    "        p2i[row['prompt']] = p\n",
    "        i2p[p] = row['prompt']\n",
    "        p+=1\n",
    "    if row['chosen'][1]['content'] not in a2i:\n",
    "        a2i[row['chosen'][1]['content']] = a\n",
    "        i2a[a] = row['chosen'][1]['content']\n",
    "        a += 1\n",
    "    if row['rejected'][1]['content'] not in a2i:\n",
    "        a2i[row['rejected'][1]['content']] = a\n",
    "        i2a[a] = row['rejected'][1]['content']\n",
    "        a += 1\n",
    "for row in dataset_test:\n",
    "    if row['prompt'] not in p2i:\n",
    "        p2i[row['prompt']] = p\n",
    "        i2p[p] = row['prompt']\n",
    "        p+=1\n",
    "    if row['chosen'][1]['content'] not in a2i:\n",
    "        a2i[row['chosen'][1]['content']] = a\n",
    "        i2a[a] = row['chosen'][1]['content']\n",
    "        a += 1\n",
    "    if row['rejected'][1]['content'] not in a2i:\n",
    "        a2i[row['rejected'][1]['content']] = a\n",
    "        i2a[a] = row['rejected'][1]['content']\n",
    "        a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing player storage...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Initialize Player Storage ---\n",
    "print(\"Initializing player storage...\")\n",
    "# Use the Player class defined above\n",
    "players = {} # Dictionary to store author_id -> Player object instance\n",
    "all_known_players = set() # Keep track of all players ever encountered\n",
    "\n",
    "def get_player(author_id):\n",
    "    \"\"\"Gets or creates a Player object for a valid author ID.\"\"\"\n",
    "    # Check specifically against None and handle empty strings if necessary\n",
    "    if author_id is not None and author_id.strip() != '' and author_id.lower() != '[deleted]':\n",
    "        if author_id not in players:\n",
    "            players[author_id] = Player() # Use the provided Player class\n",
    "            # print(f\"Created player: {author_id}\") # Optional: for debugging\n",
    "        all_known_players.add(author_id) # Track all valid players encountered\n",
    "        return players.get(author_id)\n",
    "    return None # Return None for invalid authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing matches and grouping by period...\n",
      "Gathered data for 20000/92858 rows...\n",
      "Gathered data for 40000/92858 rows...\n",
      "Gathered data for 60000/92858 rows...\n",
      "Gathered data for 80000/92858 rows...\n",
      "\n",
      "--- Data Gathering Summary ---\n",
      "Total rows processed: 92858\n",
      "Matches skipped (same author): 12\n",
      "Matches skipped (deleted/invalid author): 0\n",
      "Matches skipped (data fetch error): 0\n",
      "Total unique valid authors encountered: 60672\n",
      "Number of rating periods found: 1\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Process Matches and Group by Period ---\n",
    "print(\"Processing matches and grouping by period...\")\n",
    "matches_by_period = defaultdict(lambda: defaultdict(lambda: {'ratings': [], 'rds': [], 'outcomes': []}))\n",
    "processed_count = 0\n",
    "# max_rows_to_process = 100000 # Optional: Limit rows for testing even without streaming\n",
    "skipped_same_author = 0\n",
    "skipped_deleted = 0\n",
    "skipped_fetch_error = 0\n",
    "max_rows_to_process = 5000\n",
    "# Now iterate directly over the loaded dataset (which acts like a list/dict)\n",
    "try:\n",
    "    for i, row in enumerate(dataset):\n",
    "        processed_count += 1\n",
    "        # if processed_count > max_rows_to_process: # Apply optional limit if defined\n",
    "        #      print(f\"Reached processing limit of {max_rows_to_process} rows.\")\n",
    "        #      break\n",
    "        \n",
    "        # Extract data\n",
    "        p_ind = p2i[row.get('prompt')]\n",
    "        # Player j won\n",
    "        author_j = str((p_ind, a2i[row.get('chosen')[1]['content']]))\n",
    "        author_k = str((p_ind, a2i[row.get('rejected')[1]['content']]))\n",
    "\n",
    "        if author_j is None or author_k is None:\n",
    "            skipped_fetch_error += 1\n",
    "            continue\n",
    "        if author_j == author_k:\n",
    "            skipped_same_author += 1\n",
    "            continue\n",
    "\n",
    "        player_j = get_player(author_j)\n",
    "        player_k = get_player(author_k)\n",
    "\n",
    "        if player_j is None or player_k is None:\n",
    "            skipped_deleted += 1\n",
    "            continue\n",
    "        period = '0'\n",
    "        rating_j_current = player_j.rating\n",
    "        rd_j_current = player_j.rd\n",
    "        rating_k_current = player_k.rating\n",
    "        rd_k_current = player_k.rd\n",
    "\n",
    "        outcome_for_j = 1.0\n",
    "        outcome_for_k = 0.0\n",
    "\n",
    "        matches_by_period[period][author_j]['ratings'].append(rating_k_current)\n",
    "        matches_by_period[period][author_j]['rds'].append(rd_k_current)\n",
    "        matches_by_period[period][author_j]['outcomes'].append(outcome_for_j)\n",
    "\n",
    "        matches_by_period[period][author_k]['ratings'].append(rating_j_current)\n",
    "        matches_by_period[period][author_k]['rds'].append(rd_j_current)\n",
    "        matches_by_period[period][author_k]['outcomes'].append(outcome_for_k)\n",
    "\n",
    "        if processed_count % 20000 == 0: # Adjust print frequency as needed\n",
    "            print(f\"Gathered data for {processed_count}/{len(dataset)} rows...\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during data iteration at row {processed_count}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- Data Gathering Summary ---\")\n",
    "# ... [Summary print statements remain the same] ...\n",
    "print(f\"Total rows processed: {processed_count}\")\n",
    "print(f\"Matches skipped (same author): {skipped_same_author}\")\n",
    "print(f\"Matches skipped (deleted/invalid author): {skipped_deleted}\")\n",
    "print(f\"Matches skipped (data fetch error): {skipped_fetch_error}\")\n",
    "print(f\"Total unique valid authors encountered: {len(all_known_players)}\")\n",
    "print(f\"Number of rating periods found: {len(matches_by_period)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered data for 100000/92858 rows...\n",
      "Gathered data for 120000/92858 rows...\n",
      "\n",
      "--- Data Gathering Summary ---\n",
      "Total rows processed: 125941\n",
      "Matches skipped (same author): 12\n",
      "Matches skipped (deleted/invalid author): 0\n",
      "Matches skipped (data fetch error): 0\n",
      "Total unique valid authors encountered: 77603\n",
      "Number of rating periods found: 1\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Process Matches and Group by Period for test set---\n",
    "# Now iterate directly over the loaded dataset (which acts like a list/dict)\n",
    "try:\n",
    "    for i, row in enumerate(dataset_test):\n",
    "        processed_count += 1\n",
    "        # if processed_count > max_rows_to_process: # Apply optional limit if defined\n",
    "        #      print(f\"Reached processing limit of {max_rows_to_process} rows.\")\n",
    "        #      break\n",
    "\n",
    "        # Extract data\n",
    "        p_ind = p2i[row.get('prompt')]\n",
    "        author_j = str((p_ind, a2i[row.get('chosen')[1]['content']]))\n",
    "        author_k = str((p_ind, a2i[row.get('rejected')[1]['content']]))\n",
    "        label = row.get('labels')\n",
    "\n",
    "        if author_j is None or author_k is None:\n",
    "            skipped_fetch_error += 1\n",
    "            continue\n",
    "        if author_j == author_k:\n",
    "            skipped_same_author += 1\n",
    "            continue\n",
    "\n",
    "        player_j = get_player(author_j)\n",
    "        player_k = get_player(author_k)\n",
    "\n",
    "        if player_j is None or player_k is None:\n",
    "            skipped_deleted += 1\n",
    "            continue\n",
    "        period = '0'\n",
    "        rating_j_current = player_j.rating\n",
    "        rd_j_current = player_j.rd\n",
    "        rating_k_current = player_k.rating\n",
    "        rd_k_current = player_k.rd\n",
    "\n",
    "        # Player j won\n",
    "        outcome_for_j = 1.0\n",
    "        outcome_for_k = 0.0\n",
    "\n",
    "\n",
    "        matches_by_period[period][author_j]['ratings'].append(rating_k_current)\n",
    "        matches_by_period[period][author_j]['rds'].append(rd_k_current)\n",
    "        matches_by_period[period][author_j]['outcomes'].append(outcome_for_j)\n",
    "\n",
    "        matches_by_period[period][author_k]['ratings'].append(rating_j_current)\n",
    "        matches_by_period[period][author_k]['rds'].append(rd_j_current)\n",
    "        matches_by_period[period][author_k]['outcomes'].append(outcome_for_k)\n",
    "\n",
    "        if processed_count % 20000 == 0: # Adjust print frequency as needed\n",
    "            print(f\"Gathered data for {processed_count}/{len(dataset)} rows...\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during data iteration at row {processed_count}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- Data Gathering Summary ---\")\n",
    "# ... [Summary print statements remain the same] ...\n",
    "print(f\"Total rows processed: {processed_count}\")\n",
    "print(f\"Matches skipped (same author): {skipped_same_author}\")\n",
    "print(f\"Matches skipped (deleted/invalid author): {skipped_deleted}\")\n",
    "print(f\"Matches skipped (data fetch error): {skipped_fetch_error}\")\n",
    "print(f\"Total unique valid authors encountered: {len(all_known_players)}\")\n",
    "print(f\"Number of rating periods found: {len(matches_by_period)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating ratings period by period...\n",
      "Processing period: 0\n",
      "-> Completed updates for 77603 active players. Applied inactivity update for 0 players.\n",
      "Rating updates complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Run Glicko-2 Updates Period by Period ---\n",
    "print(\"\\nUpdating ratings period by period...\")\n",
    "# ... [Rating update loop remains the same as previous response] ...\n",
    "sorted_periods = sorted(matches_by_period.keys())\n",
    "\n",
    "for period in sorted_periods:\n",
    "    print(f\"Processing period: {period}\")\n",
    "    players_in_period = set(matches_by_period[period].keys())\n",
    "\n",
    "    # Identify players who *didn't* compete in this period but existed before\n",
    "    inactive_players_in_period = all_known_players - players_in_period\n",
    "\n",
    "    # Apply Step 6: Update RD for inactive players\n",
    "    inactive_update_count = 0\n",
    "    for author_id in inactive_players_in_period:\n",
    "        player = players.get(author_id)\n",
    "        if player: # Should always exist if in all_known_players\n",
    "             try:\n",
    "                 player.did_not_compete()\n",
    "                 inactive_update_count += 1\n",
    "             except Exception as e:\n",
    "                 print(f\"Error calling did_not_compete for {author_id} in period {period}: {e}\")\n",
    "\n",
    "    # Apply Steps 3-5: Update rating, RD, vol for active players\n",
    "    updates_count = 0\n",
    "    for author_id in players_in_period:\n",
    "        player = players.get(author_id)\n",
    "        if not player: continue # Should not happen if key exists, but safe check\n",
    "\n",
    "        period_data = matches_by_period[period][author_id]\n",
    "        opponent_ratings = period_data['ratings']\n",
    "        opponent_rds = period_data['rds']\n",
    "        outcomes = period_data['outcomes']\n",
    "\n",
    "        # Ensure we have opponents before calling update\n",
    "        if opponent_ratings:\n",
    "            try:\n",
    "                player.update_player(opponent_ratings, opponent_rds, outcomes)\n",
    "                updates_count += 1\n",
    "            except OverflowError:\n",
    "                 print(f\"OverflowError encountered updating player {author_id} in period {period}. Skipping update.\")\n",
    "                 # This can happen with extreme rating differences or RDs. Might indicate need for parameter tuning or data cleaning.\n",
    "                 # Consider logging player state: player.rating, player.rd, player.vol and opponent data\n",
    "            except FloatingPointError as fpe:\n",
    "                print(f\"FloatingPointError encountered updating player {author_id} in period {period}: {fpe}. Skipping update.\")\n",
    "            except Exception as e:\n",
    "                 print(f\"Error updating player {author_id} in period {period}: {e}\")\n",
    "\n",
    "\n",
    "    print(f\"-> Completed updates for {updates_count} active players. Applied inactivity update for {inactive_update_count} players.\")\n",
    "\n",
    "\n",
    "print(\"Rating updates complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Glicko-2 Ratings for Authors ---\n",
      "Displaying top 20 and bottom 10 authors:\n",
      "               author       rating  deviation (RD)  volatility\n",
      "35363   (8732, 35336)  1994.563819       76.398776    0.063120\n",
      "30890   (7644, 30870)  1994.563819       76.398776    0.063120\n",
      "35629   (8794, 35602)  1994.016832       77.239280    0.062963\n",
      "47871  (11721, 47822)  1993.445098       78.108149    0.062811\n",
      "48371  (11844, 48322)  1993.445098       78.108149    0.062811\n",
      "49334  (12076, 49285)  1992.220354       79.937647    0.062522\n",
      "26105   (6471, 26094)  1990.148941       82.940136    0.062126\n",
      "13012   (3235, 13011)  1989.386177       84.018741    0.062003\n",
      "17569   (4359, 17566)  1989.386177       84.018741    0.062003\n",
      "11883   (2957, 11883)  1987.734235       86.308532    0.061770\n",
      "17392   (4316, 17389)  1987.734235       86.308532    0.061770\n",
      "16160   (4013, 16157)  1985.889097       88.796359    0.061555\n",
      "15322   (3805, 15320)  1985.889097       88.796359    0.061555\n",
      "19942   (4950, 19937)  1985.889097       88.796359    0.061555\n",
      "24625   (6106, 24616)  1985.889097       88.796359    0.061555\n",
      "62558  (15242, 62500)  1985.889097       88.796359    0.061555\n",
      "12338   (3069, 12337)  1985.889097       88.796359    0.061555\n",
      "24623   (6106, 24614)  1985.889097       88.796359    0.061555\n",
      "21788   (5411, 21782)  1984.883168       90.123755    0.061453\n",
      "35735   (8820, 35708)  1983.814762       91.512517    0.061355\n",
      "...\n",
      "               author       rating  deviation (RD)  volatility\n",
      "18619   (4620, 18616)  1009.126240       81.902033    0.062254\n",
      "49337  (12076, 49288)  1006.554902       78.108149    0.062811\n",
      "73062  (15819, 72990)  1006.554902       78.108149    0.062811\n",
      "42524  (10461, 42480)  1005.983168       77.239280    0.062963\n",
      "35632   (8794, 35605)  1005.983168       77.239280    0.062963\n",
      "30891   (7644, 30871)  1005.436181       76.398776    0.063120\n",
      "46046  (11292, 45997)  1004.912367       75.585128    0.063283\n",
      "62433  (15210, 62375)  1003.928607       74.032895    0.063625\n",
      "6710     (1678, 6710)  1000.006611       67.491064    0.065738\n",
      "6875     (1719, 6875)   996.753739       61.541390    0.069525\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Display Results ---\n",
    "print(\"\\n--- Final Glicko-2 Ratings for Authors ---\")\n",
    "# ... [Result display remains the same as previous response] ...\n",
    "author_ratings = []\n",
    "skipped_final_rating = 0\n",
    "for author_id, player in players.items():\n",
    "    try:\n",
    "        # Add check for NaN/Inf before appending\n",
    "        rating_val = player.rating\n",
    "        rd_val = player.rd\n",
    "        vol_val = player.vol\n",
    "        if not (math.isfinite(rating_val) and math.isfinite(rd_val) and math.isfinite(vol_val)):\n",
    "            print(f\"Warning: Non-finite values for player {author_id}. Rating={rating_val}, RD={rd_val}, Vol={vol_val}. Skipping.\")\n",
    "            skipped_final_rating += 1\n",
    "            continue\n",
    "\n",
    "        author_ratings.append({\n",
    "            \"author\": author_id,\n",
    "            \"rating\": rating_val, # Uses the property getter\n",
    "            \"deviation (RD)\": rd_val, # Uses the property getter\n",
    "            \"volatility\": vol_val\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving final rating for {author_id}: {e}\")\n",
    "        skipped_final_rating += 1\n",
    "\n",
    "\n",
    "if skipped_final_rating > 0:\n",
    "    print(f\"\\nNote: Skipped retrieving final ratings for {skipped_final_rating} authors due to errors or non-finite values.\")\n",
    "\n",
    "# Sort by rating descending for readability\n",
    "results_df = pd.DataFrame(author_ratings)\n",
    "\n",
    "if not results_df.empty:\n",
    "    # Ensure columns are numeric before sorting\n",
    "    results_df['rating'] = pd.to_numeric(results_df['rating'], errors='coerce')\n",
    "    results_df['deviation (RD)'] = pd.to_numeric(results_df['deviation (RD)'], errors='coerce')\n",
    "    results_df['volatility'] = pd.to_numeric(results_df['volatility'], errors='coerce')\n",
    "    results_df.dropna(subset=['rating'], inplace=True) # Remove rows where rating became NaN\n",
    "\n",
    "if not results_df.empty:\n",
    "    results_df = results_df.sort_values(by=\"rating\", ascending=False)\n",
    "\n",
    "    # Display top N and bottom N for brevity, or the whole list\n",
    "    pd.set_option('display.max_rows', 100) # Show more rows if needed\n",
    "    print(f\"Displaying top {min(20, len(results_df))} and bottom {min(10, len(results_df))} authors:\")\n",
    "    print(results_df.head(20))\n",
    "    if len(results_df) > 30:\n",
    "        print(\"...\")\n",
    "        print(results_df.tail(10))\n",
    "    elif len(results_df) > 20:\n",
    "         print(\"...\") # Just indicate truncation if list is moderately long\n",
    "else:\n",
    "    print(\"No valid final ratings could be generated or displayed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing 77603 valid results...\n",
      "\n",
      "Displaying top 20 authors (incl. normalized scores):\n",
      "               author     rating  rating_norm  deviation (RD)  rd_norm  volatility  volatility_norm\n",
      "35363   (8732, 35336)  1994.5638       1.0000         76.3988   0.0649      0.0631           0.3339\n",
      "30890   (7644, 30870)  1994.5638       1.0000         76.3988   0.0649      0.0631           0.3339\n",
      "35629   (8794, 35602)  1994.0168       0.9995         77.2393   0.0686      0.0630           0.3176\n",
      "47871  (11721, 47822)  1993.4451       0.9989         78.1081   0.0724      0.0628           0.3018\n",
      "48371  (11844, 48322)  1993.4451       0.9989         78.1081   0.0724      0.0628           0.3018\n",
      "49334  (12076, 49285)  1992.2204       0.9977         79.9376   0.0804      0.0625           0.2718\n",
      "26105   (6471, 26094)  1990.1489       0.9956         82.9401   0.0935      0.0621           0.2306\n",
      "13012   (3235, 13011)  1989.3862       0.9948         84.0187   0.0983      0.0620           0.2178\n",
      "17569   (4359, 17566)  1989.3862       0.9948         84.0187   0.0983      0.0620           0.2178\n",
      "11883   (2957, 11883)  1987.7342       0.9932         86.3085   0.1083      0.0618           0.1936\n",
      "17392   (4316, 17389)  1987.7342       0.9932         86.3085   0.1083      0.0618           0.1936\n",
      "16160   (4013, 16157)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "15322   (3805, 15320)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "19942   (4950, 19937)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "24625   (6106, 24616)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "62558  (15242, 62500)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "12338   (3069, 12337)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "24623   (6106, 24614)  1985.8891       0.9913         88.7964   0.1191      0.0616           0.1711\n",
      "21788   (5411, 21782)  1984.8832       0.9903         90.1238   0.1249      0.0615           0.1605\n",
      "35735   (8820, 35708)  1983.8148       0.9892         91.5125   0.1310      0.0614           0.1504\n",
      "...\n",
      "\n",
      "Displaying bottom 10 authors (incl. normalized scores):\n",
      "               author     rating  rating_norm  deviation (RD)  rd_norm  volatility  volatility_norm\n",
      "18619   (4620, 18616)  1009.1262       0.0124         81.9020   0.0890      0.0623           0.2438\n",
      "49337  (12076, 49288)  1006.5549       0.0098         78.1081   0.0724      0.0628           0.3018\n",
      "73062  (15819, 72990)  1006.5549       0.0098         78.1081   0.0724      0.0628           0.3018\n",
      "42524  (10461, 42480)  1005.9832       0.0092         77.2393   0.0686      0.0630           0.3176\n",
      "35632   (8794, 35605)  1005.9832       0.0092         77.2393   0.0686      0.0630           0.3176\n",
      "30891   (7644, 30871)  1005.4362       0.0087         76.3988   0.0649      0.0631           0.3339\n",
      "46046  (11292, 45997)  1004.9124       0.0082         75.5851   0.0614      0.0633           0.3508\n",
      "62433  (15210, 62375)  1003.9286       0.0072         74.0329   0.0546      0.0636           0.3864\n",
      "6710     (1678, 6710)  1000.0066       0.0033         67.4911   0.0260      0.0657           0.6062\n",
      "6875     (1719, 6875)   996.7537       0.0000         61.5414   0.0000      0.0695           1.0000\n",
      "\n",
      "Results saved to author_ratings_normalized.csv\n",
      "\n",
      "Current time: 2025-05-22 18:42:33\n",
      "Total execution time: 23.28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(author_ratings)\n",
    "\n",
    "# --- Normalization Step ---\n",
    "if not results_df.empty:\n",
    "    print(f\"\\nNormalizing {len(results_df)} valid results...\")\n",
    "    # Min-Max Normalization (scaling to [0, 1])\n",
    "\n",
    "    # Rating\n",
    "    r_min = results_df['rating'].min()\n",
    "    r_max = results_df['rating'].max()\n",
    "    if (r_max - r_min) != 0:\n",
    "        results_df['rating_norm'] = (results_df['rating'] - r_min) / (r_max - r_min)\n",
    "    else:\n",
    "        results_df['rating_norm'] = 0.5 # Assign midpoint if all values are the same\n",
    "\n",
    "    # Deviation (RD)\n",
    "    rd_min = results_df['deviation (RD)'].min()\n",
    "    rd_max = results_df['deviation (RD)'].max()\n",
    "    if (rd_max - rd_min) != 0:\n",
    "        results_df['rd_norm'] = (results_df['deviation (RD)'] - rd_min) / (rd_max - rd_min)\n",
    "    else:\n",
    "        results_df['rd_norm'] = 0.5\n",
    "\n",
    "    # Volatility\n",
    "    v_min = results_df['volatility'].min()\n",
    "    v_max = results_df['volatility'].max()\n",
    "    if (v_max - v_min) != 0:\n",
    "        results_df['volatility_norm'] = (results_df['volatility'] - v_min) / (v_max - v_min)\n",
    "    else:\n",
    "        results_df['volatility_norm'] = 0.5\n",
    "\n",
    "    # Sort by original rating\n",
    "    results_df = results_df.sort_values(by=\"rating\", ascending=False)\n",
    "\n",
    "    # Display selected columns including normalized ones\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    pd.set_option('display.width', 120) # Adjust width for better display\n",
    "    print(f\"\\nDisplaying top {min(20, len(results_df))} authors (incl. normalized scores):\")\n",
    "    # Select columns to display\n",
    "    display_cols = ['author', 'rating', 'rating_norm', 'deviation (RD)', 'rd_norm', 'volatility', 'volatility_norm']\n",
    "    print(results_df[display_cols].head(20).round(4)) # Round for display\n",
    "\n",
    "    if len(results_df) > 20:\n",
    "        print(\"...\")\n",
    "        print(f\"\\nDisplaying bottom {min(10, len(results_df))} authors (incl. normalized scores):\")\n",
    "        print(results_df[display_cols].tail(min(10, max(0, len(results_df)))).round(4))\n",
    "\n",
    "else:\n",
    "    print(\"No valid final ratings could be generated or displayed.\")\n",
    "df = results_df\n",
    "auth = df['author'].apply(lambda x: re.sub('[^A-Za-z0-9,]', '', str(x))).str.split(',')\n",
    "prompts = auth.apply(lambda x: i2p[int(x[0])])\n",
    "answers = auth.apply(lambda x: i2a[int(x[1])])\n",
    "df['question'] = prompts\n",
    "df['answer'] = answers\n",
    "\n",
    "# Optionally, save to CSV (including normalized columns)\n",
    "try:\n",
    "    if not df.empty:\n",
    "        df.to_csv(\"author_ratings_normalized.csv\", index=False, float_format='%.6f')\n",
    "        print(\"\\nResults saved to author_ratings_normalized.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving results to CSV: {e}\")\n",
    "end_time = time.time()\n",
    "print(f\"\\nCurrent time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries that map text to indices\n",
    "import pickle\n",
    "def save_dictionary(dictionary, filename):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a file using pickle.\n",
    "    \n",
    "    Args:\n",
    "        dictionary (dict): The dictionary to save\n",
    "        filename (str): The name of the file to save to\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "    print(f\"Dictionary saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to p2i\n",
      "Dictionary saved to i2a\n",
      "Dictionary saved to i2p\n",
      "Dictionary saved to a2i\n"
     ]
    }
   ],
   "source": [
    "save_dictionary(p2i, 'p2i')\n",
    "save_dictionary(i2a, 'i2a')\n",
    "save_dictionary(i2p, 'i2p')\n",
    "save_dictionary(a2i, 'a2i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>deviation (RD)</th>\n",
       "      <th>volatility</th>\n",
       "      <th>rating_norm</th>\n",
       "      <th>rd_norm</th>\n",
       "      <th>volatility_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77603.000000</td>\n",
       "      <td>77603.000000</td>\n",
       "      <td>77603.000000</td>\n",
       "      <td>77603.000000</td>\n",
       "      <td>77603.000000</td>\n",
       "      <td>77603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1496.322613</td>\n",
       "      <td>236.932846</td>\n",
       "      <td>0.060015</td>\n",
       "      <td>0.500665</td>\n",
       "      <td>0.766646</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>215.695561</td>\n",
       "      <td>29.360423</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.016053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>996.753739</td>\n",
       "      <td>61.541146</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1252.681917</td>\n",
       "      <td>227.735397</td>\n",
       "      <td>0.059997</td>\n",
       "      <td>0.256490</td>\n",
       "      <td>0.726444</td>\n",
       "      <td>0.009154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>253.404596</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.504351</td>\n",
       "      <td>0.838645</td>\n",
       "      <td>0.009782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1747.318083</td>\n",
       "      <td>253.404608</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.838645</td>\n",
       "      <td>0.009782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1994.563819</td>\n",
       "      <td>290.318965</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating  deviation (RD)    volatility   rating_norm       rd_norm  volatility_norm\n",
       "count  77603.000000    77603.000000  77603.000000  77603.000000  77603.000000     77603.000000\n",
       "mean    1496.322613      236.932846      0.060015      0.500665      0.766646         0.011047\n",
       "std      215.695561       29.360423      0.000154      0.216169      0.128336         0.016053\n",
       "min      996.753739       61.541146      0.059909      0.000000      0.000000         0.000000\n",
       "25%     1252.681917      227.735397      0.059997      0.256490      0.726444         0.009154\n",
       "50%     1500.000000      253.404596      0.060003      0.504351      0.838645         0.009782\n",
       "75%     1747.318083      253.404608      0.060003      0.752212      0.838645         0.009782\n",
       "max     1994.563819      290.318965      0.069525      1.000000      1.000000         1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Provided Glicko-2 Player Class ---\n",
    "class Player:\n",
    "    # Class attribute\n",
    "    # The system constant, which constrains\n",
    "    # the change in volatility over time.\n",
    "    _tau = 0.5\n",
    "\n",
    "    def getRating(self):\n",
    "        return (self.__rating * 173.7178) + 1500\n",
    "\n",
    "    def setRating(self, rating):\n",
    "        self.__rating = (rating - 1500) / 173.7178\n",
    "\n",
    "    rating = property(getRating, setRating)\n",
    "\n",
    "    def getRd(self):\n",
    "        return self.__rd * 173.7178\n",
    "\n",
    "    def setRd(self, rd):\n",
    "        self.__rd = rd / 173.7178\n",
    "\n",
    "    rd = property(getRd, setRd)\n",
    "\n",
    "    def __init__(self, rating = 1500, rd = 350, vol = 0.06):\n",
    "        # For testing purposes, preload the values\n",
    "        # assigned to an unrated player.\n",
    "        self.setRating(rating)\n",
    "        self.setRd(rd)\n",
    "        self.vol = vol\n",
    "\n",
    "    def _preRatingRD(self):\n",
    "        \"\"\" Calculates and updates the player's rating deviation for the\n",
    "        beginning of a rating period.\n",
    "\n",
    "        preRatingRD() -> None\n",
    "\n",
    "        \"\"\"\n",
    "        self.__rd = math.sqrt(math.pow(self.__rd, 2) + math.pow(self.vol, 2))\n",
    "\n",
    "    def update_player(self, rating_list, RD_list, outcome_list):\n",
    "        \"\"\" Calculates the new rating and rating deviation of the player.\n",
    "\n",
    "        update_player(list[int], list[int], list[bool]) -> None\n",
    "        Docstring notes list[bool] for outcome, but expects numeric 0, 0.5, 1\n",
    "        \"\"\"\n",
    "        # Convert the opponent rating and rating deviation values for internal use.\n",
    "        rating_list = [(x - 1500) / 173.7178 for x in rating_list]\n",
    "        RD_list = [x / 173.7178 for x in RD_list]\n",
    "\n",
    "        v = self._v(rating_list, RD_list)\n",
    "        self.vol = self._newVol(rating_list, RD_list, outcome_list, v)\n",
    "        self._preRatingRD() # Applies Step 2 (modified RD) internally *after* vol update\n",
    "\n",
    "        self.__rd = 1 / math.sqrt((1 / math.pow(self.__rd, 2)) + (1 / v))\n",
    "\n",
    "        tempSum = 0\n",
    "        for i in range(len(rating_list)):\n",
    "            tempSum += self._g(RD_list[i]) * \\\n",
    "                       (outcome_list[i] - self._E(rating_list[i], RD_list[i]))\n",
    "        self.__rating += math.pow(self.__rd, 2) * tempSum\n",
    "\n",
    "\n",
    "    def _newVol(self, rating_list, RD_list, outcome_list, v):\n",
    "        \"\"\" Calculating the new volatility as per the Glicko2 system.\n",
    "\n",
    "        _newVol(list, list, list) -> float\n",
    "\n",
    "        \"\"\"\n",
    "         # Convergence tolerance for the iteration\n",
    "        CONVERGENCE_TOLERANCE = 0.000001\n",
    "        i = 0\n",
    "        delta = self._delta(rating_list, RD_list, outcome_list, v)\n",
    "        a = math.log(math.pow(self.vol, 2))\n",
    "        tau = self._tau\n",
    "        # Use rating deviation (phi) from the start of the period for calculation\n",
    "        pre_rating_rd_sq = math.pow(self.__rd, 2) + math.pow(self.vol, 2) # RD^2 + vol^2 before update\n",
    "\n",
    "        # Simplified conditions for the Illinois algorithm based on Glickman's paper\n",
    "        A = a\n",
    "        if (delta**2 > pre_rating_rd_sq + v):\n",
    "             B = math.log(delta**2 - pre_rating_rd_sq - v)\n",
    "        else:\n",
    "             k = 1\n",
    "             while self._f(a - k * tau, delta, v, a, tau) < 0:\n",
    "                  k = k + 1\n",
    "             B = a - k * tau\n",
    "\n",
    "        fA = self._f(A, delta, v, a, tau)\n",
    "        fB = self._f(B, delta, v, a, tau)\n",
    "\n",
    "        while math.fabs(B - A) > CONVERGENCE_TOLERANCE:\n",
    "            C = A + (A - B) * fA / (fB - fA)\n",
    "            fC = self._f(C, delta, v, a, tau)\n",
    "            if fC * fB < 0:\n",
    "                 A = B\n",
    "                 fA = fB\n",
    "            else:\n",
    "                 fA = fA / 2.0\n",
    "            B = C\n",
    "            fB = fC\n",
    "\n",
    "        return math.exp(A / 2.0)\n",
    "\n",
    "    # Helper function for the volatility calculation's iterative method\n",
    "    def _f(self, x, delta, v, a, tau):\n",
    "        ex = math.exp(x)\n",
    "        # Use rating deviation (phi) from the start of the period for calculation\n",
    "        pre_rating_rd_sq = math.pow(self.__rd, 2) + math.pow(self.vol, 2) # RD^2 + vol^2 before update\n",
    "        d_sq = pre_rating_rd_sq + v + ex # Denominator squared term estimate\n",
    "\n",
    "        # Handle potential division by zero or log of non-positive if d_sq is problematic\n",
    "        if d_sq <= 0: return -1 # Or some other indicator of error/boundary condition\n",
    "\n",
    "        term1 = ex * (delta**2 - pre_rating_rd_sq - v - ex) / (2 * d_sq**2) if d_sq else 0\n",
    "        term2 = (x - a) / tau**2\n",
    "        return term1 - term2\n",
    "\n",
    "\n",
    "    def _delta(self, rating_list, RD_list, outcome_list, v):\n",
    "        \"\"\" The delta function of the Glicko2 system.\n",
    "\n",
    "        _delta(list, list, list) -> float\n",
    "\n",
    "        \"\"\"\n",
    "        tempSum = 0\n",
    "        for i in range(len(rating_list)):\n",
    "            tempSum += self._g(RD_list[i]) * (outcome_list[i] - self._E(rating_list[i], RD_list[i]))\n",
    "        return v * tempSum\n",
    "\n",
    "    def _v(self, rating_list, RD_list):\n",
    "        \"\"\" The v function of the Glicko2 system.\n",
    "\n",
    "        _v(list[int], list[int]) -> float\n",
    "\n",
    "        \"\"\"\n",
    "        tempSum = 0\n",
    "        for i in range(len(rating_list)):\n",
    "            tempE = self._E(rating_list[i], RD_list[i])\n",
    "            tempSum += math.pow(self._g(RD_list[i]), 2) * tempE * (1 - tempE)\n",
    "\n",
    "        # Avoid division by zero if tempSum is zero (e.g., no opponents)\n",
    "        if tempSum == 0:\n",
    "            # Handle this case: perhaps return a very large number or raise error\n",
    "            # Glickman's paper suggests V -> infinity, so 1/V -> 0.\n",
    "            # Returning a very small inverse V, but update_player uses 1/V. Let's return a large V.\n",
    "             return float('inf') # Or a very large number\n",
    "        return 1 / tempSum\n",
    "\n",
    "    def _E(self, p2rating, p2RD):\n",
    "        \"\"\" The Glicko E function.\n",
    "\n",
    "        _E(int) -> float\n",
    "\n",
    "        \"\"\"\n",
    "        return 1 / (1 + math.exp(-1 * self._g(p2RD) * \\\n",
    "                                   (self.__rating - p2rating)))\n",
    "\n",
    "    def _g(self, RD):\n",
    "        \"\"\" The Glicko2 g(RD) function.\n",
    "\n",
    "        _g() -> float\n",
    "\n",
    "        \"\"\"\n",
    "        return 1 / math.sqrt(1 + 3 * math.pow(RD, 2) / math.pow(math.pi, 2))\n",
    "\n",
    "    def did_not_compete(self):\n",
    "        \"\"\" Applies Step 6 of the algorithm. Use this for\n",
    "        players who did not compete in the rating period.\n",
    "\n",
    "        did_not_compete() -> None\n",
    "\n",
    "        \"\"\"\n",
    "        self._preRatingRD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
